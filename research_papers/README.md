# Research Papers and Updates
- This section contains good research papers in the GenAI, NLP and LLm space. The format for this section is 
- Title of the Paper
- Brief Abstract
- Link to the paper
- --------------
- **Title:** LMAgent: A Large-scale Multimodal Agents Society for Multi-user Simulation
- **Abstract:** This paper introduces LMAgent, a large-scale, multimodal society of AI agents built on multimodal large language models (LLMs) for simulating complex social behaviors in an e-commerce setting. The agents can engage in various human-like activities—such as chatting, browsing products, making purchases, writing reviews, and even participating in live-streamed e-commerce. To improve the realism and efficiency of their simulations, the authors employ a self-consistency prompting method that enhances agents’ decision-making and propose a fast-memory approach combined with a small-world model to scale up to over 10,000 interacting agents. Experiments show that LMAgent’s simulated agents behave comparably to humans in key behavioral metrics, and the system reveals emerging phenomena like herd behavior, underscoring its value in studying credible, large-scale social dynamics.
- **Link:** https://arxiv.org/pdf/2412.09237
- --------------
- **Title:** When Text Embedding Meets Large Language
  Model: A Comprehensive Survey
- **Abstract:** This survey examines how large language models (LLMs) influence and interact with text embeddings—an essential technology for tasks like semantic matching, clustering, and information retrieval. It categorizes current work into three main themes: (1) using LLMs to enhance traditional embeddings, (2) leveraging LLMs directly as embedder models, and (3) applying LLMs to interpret and understand existing embeddings. Rather than focusing on specific end-use cases, it provides a broad, structured overview of how LLMs enrich embedding methods, their generation, and their analysis. The survey also revisits longstanding challenges from the pre-LLM era and explores new issues emerging with LLM integration. Finally, it presents future directions to address these theoretical and practical challenges, guiding the ongoing evolution of text embeddings in the LLM era.
- **Link:** https://arxiv.org/pdf/2412.09165
